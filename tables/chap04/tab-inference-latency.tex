
\begin{table}[ht]
\caption{大型语言模型推理的时间消耗与网络任务所需时效对比}

\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}ccccc@{}}
\toprule
项目                              & 模型         & 量化方式   & 运行GPU              & 延迟\cite{colab2023}  \\ \midrule
理论                            & Mistral-7B    & 16位        & RTX 4090(1008 GB/s)      & 14.1ms/Token               \\
理论                            & Mistral-7B    & 8位         & RTX 4090                 & \textbf{7ms/Token}         \\
实际                            & ChatGLM3-6B   & 16位        & RTX 4090(2022)           & 16ms/Token                 \\
实际                            & ChatGLM3-6B   & 16位        & V100 32GB (2017)         & 32ms/Token                 \\
实际                            & Qwen-7B       & 16位        & RTX 4090(2022)           & 19ms/Token                 \\
拥塞控制                          & /             & /              & /                        & 1$\sim$3 RTT (10$\sim$50ms) \\
自适应比特率流                   & /             & /              & /                        & 每个块 (1-5s) \\
梯度压缩                          & /             & /              & /                        & 每次迭代 \\
\bottomrule
\end{tabular}
}
\label{tab:infer_latn}
\end{table}
